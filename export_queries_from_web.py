#!/usr/bin/env python3
"""
–≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö queries –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ HTML —Ñ–∞–π–ª–∞ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–ª—è –≤–µ—Ä—Å–∏–∏ 1.0
"""

import re
import html
from datetime import datetime
from bs4 import BeautifulSoup

def clean_text(text):
    """–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç HTML —Ç–µ–≥–æ–≤ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"""
    # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
    text = re.sub(r'<[^>]+>', '', text)
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    text = ' '.join(text.split())
    return text.strip()

def export_queries_from_html():
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ queries –∏–∑ HTML —Ñ–∞–π–ª–∞"""
    try:
        html_file = '/Users/extndd/Downloads/513513513.html'
        print(f"üîç –ß–∏—Ç–∞–µ–º HTML —Ñ–∞–π–ª: {html_file}")
        
        # –ß–∏—Ç–∞–µ–º HTML —Ñ–∞–π–ª
        with open(html_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º BeautifulSoup –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
        soup = BeautifulSoup(content, 'html.parser')
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        rows = soup.find_all('tr')
        queries = []
        
        for row in rows:
            cells = row.find_all('td')
            if len(cells) >= 4:
                try:
                    # –ù–æ–º–µ—Ä –≤ —Ç–∞–±–ª–∏—Ü–µ
                    num_cell = cells[0]
                    if 'fw-bold' in num_cell.get('class', []):
                        num = clean_text(num_cell.get_text())
                        
                        # –°—Å—ã–ª–∫–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ
                        link_cell = cells[1]
                        link = link_cell.find('a')
                        if link:
                            url = link.get('href', '')
                            title = clean_text(link.get_text())
                            
                            # Thread ID
                            thread_cell = cells[2]
                            thread_span = thread_cell.find('span', class_='text-primary')
                            thread_id = clean_text(thread_span.get_text()) if thread_span else '–ù–µ –∑–∞–¥–∞–Ω'
                            
                            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
                            count_cell = cells[4] if len(cells) > 4 else cells[3]
                            count_span = count_cell.find('span', class_='text-info')
                            items_count = clean_text(count_span.get_text()) if count_span else '0'
                            
                            queries.append({
                                'num': num,
                                'title': title,
                                'url': html.unescape(url),
                                'thread_id': thread_id,
                                'items_count': items_count
                            })
                except Exception as e:
                    continue
        
        print(f'‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(queries)} queries –≤ HTML —Ñ–∞–π–ª–µ')
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç
        export_filename = f'queries_export_from_web_clean_v1.0_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
        
        with open(export_filename, 'w', encoding='utf-8') as f:
            f.write('=' * 80 + '\n')
            f.write('KUFAR SEARCHER - –≠–ö–°–ü–û–†–¢ QUERIES –ò–ó –í–ï–ë-–ò–ù–¢–ï–†–§–ï–ô–°–ê (–í–ï–†–°–ò–Ø 1.0)\n')
            f.write('=' * 80 + '\n')
            f.write(f'–î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n')
            f.write(f'–í—Å–µ–≥–æ queries: {len(queries)}\n')
            f.write(f'–ò—Å—Ç–æ—á–Ω–∏–∫: –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Railway (https://web-production-81c7.up.railway.app/queries)\n')
            f.write('=' * 80 + '\n\n')
            
            for i, query in enumerate(queries, 1):
                f.write(f'QUERY #{i}\n')
                f.write('-' * 40 + '\n')
                f.write(f'–ù–æ–º–µ—Ä –≤ —Ç–∞–±–ª–∏—Ü–µ: {query["num"]}\n')
                f.write(f'–ù–∞–∑–≤–∞–Ω–∏–µ: {query["title"]}\n')
                f.write(f'URL: {query["url"]}\n')
                f.write(f'Thread ID: {query["thread_id"]}\n')
                f.write(f'–ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {query["items_count"]}\n')
                f.write('\n')
            
            f.write('=' * 80 + '\n')
            f.write('–ö–û–ù–ï–¶ –≠–ö–°–ü–û–†–¢–ê\n')
            f.write('=' * 80 + '\n')
        
        print(f'‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {export_filename}')
        print(f'üìä –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ queries: {len(queries)}')
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_items = sum(int(q['items_count']) for q in queries if q['items_count'].isdigit())
        active_queries = len([q for q in queries if int(q['items_count']) > 0 if q['items_count'].isdigit()])
        
        print(f'üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:')
        print(f'   ‚Ä¢ –í—Å–µ–≥–æ queries: {len(queries)}')
        print(f'   ‚Ä¢ –° –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏: {active_queries}')
        print(f'   ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total_items}')
        
        return export_filename
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
        return None

if __name__ == "__main__":
    export_queries_from_html()
